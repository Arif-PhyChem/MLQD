{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d898807b",
      "metadata": {
        "id": "d898807b"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/Arif-PhyChem/MLQD/blob/main/Jupyter_Notebooks/AIQD_SB.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "12ca3d5f",
      "metadata": {
        "id": "12ca3d5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceada1ec-8f50-4e83-feae-3e6f10a2aaa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlqd in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: MLatom in /usr/local/lib/python3.9/dist-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from MLatom) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from MLatom) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->MLatom) (4.39.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->MLatom) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->MLatom) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.9/dist-packages (0.2.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from hyperopt) (3.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from hyperopt) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from hyperopt) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#Install MLQD and other packages\n",
        "!pip install mlqd \n",
        "!pip install MLatom\n",
        "!pip install tensorflow hyperopt scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "31f063cf",
      "metadata": {
        "id": "31f063cf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from mlqd.evolution import quant_dyn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaed8821",
      "metadata": {
        "id": "aaed8821"
      },
      "source": [
        "We consider spin-boson model as was consider in our published study https://iopscience.iop.org/article/10.1088/1367-2630/ac3261\n",
        "\n",
        "\\begin{align} \\label{eq:sb}\n",
        "    \\boldsymbol{\\rm H} = \\frac{1}{2}\\epsilon \\boldsymbol{\\sigma}_{z}  + \\frac{1}{2}\\Delta \\boldsymbol{\\sigma}_{x} + \\sum_{k} \\omega_k \\boldsymbol{\\rm b}_k^\\dagger \\boldsymbol{\\rm b}_k + \\frac{1}{2} \\boldsymbol{\\sigma}_z \\boldsymbol{\\rm F},\n",
        "\\end{align}\n",
        "here $\\boldsymbol{\\sigma}_z$ and $\\boldsymbol{\\sigma}_x$ are the Pauli matrices, i.e., $\\boldsymbol{\\sigma}_z = | e\\rangle \\langle e| - | g \\rangle \\langle g|$, $\\boldsymbol{\\sigma}_x =  |e\\rangle \\langle g| + | g \\rangle \\langle  e|$. $\\epsilon$ and $\\Delta$ are the energy bias and tunneling matrix element, respectively. $\\omega_k$ is the frequency corresponds to $k$ bath mode and $\\boldsymbol{\\rm b}_k^\\dagger$ is the corresponding bath creation operator. $\\boldsymbol{\\rm F}$ is the interaction operator and can be expressed as $\\boldsymbol{\\rm F} = \\sum_k \\frac{c_k}{\\sqrt{2 \\omega_k}} (\\boldsymbol{\\rm b}_k + \\boldsymbol{\\rm b}_k^\\dagger)$, where $c_k$ denotes the coupling strength between system and $k$ bath mode. Initially, we consider that the system is in the excited state $|e\\rangle$ (by absorbing a photon of energy equal to the energy gap between the two states) and we let the system to be relaxed by exchanging its energy with the bath.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d5a2d0",
      "metadata": {
        "id": "d7d5a2d0"
      },
      "source": [
        "We consider the Drude–Lorentz spectral density \n",
        "$$\n",
        "    J_{\\text{b}}(\\omega)=2 \\lambda \\frac{\\omega \\gamma}{\\omega^{2}+\\gamma^{2}},\n",
        "$$\n",
        "with $\\gamma$ as characteristic frequency and $\\lambda$ as the reorganization energy.\n",
        "\n",
        "We use the Hierarchical equations of motion (HEOM) approach and generate data for all the possible combinations of the following parameters: $\\epsilon = \\{0, 1\\}$, the reorganization energy $\\lambda \\in \\{0.1$, $0.2$, $0.3$, $0.4$, $0.5$, $0.6$, $0.7$, $0.8$, $0.9$, $1.0 \\},$ the characteristic frequency $\\gamma \\in \\{1$, $2$, $3$, $4$, $5$, $6$, $7$, $8$, $9$, $10\\},$ inverse temperature $\\beta = 1/T \\in \\{0.1$, $0.25$, $0.5$, $0.75$, $1\\}$. It should be noted that all parameters are in atomic units (a.u.). \n",
        "\n",
        "We generate 500 trajectories for each case (symmetric and asymmetric $\\epsilon = \\{0, 1\\}$) and then train a CNN model following the AIQD approach. You can grab the trajectories from our **QD3SET-1 database** [https://arxiv.org/abs/2301.12096]. **However, here for the sake of demonstration, we provide 20 trajectories in the ```sb_data``` folder.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9205b0dc",
      "metadata": {
        "id": "9205b0dc"
      },
      "source": [
        "## AIQD approach\n",
        "\n",
        "We prepare our training using parameters {$\\epsilon$, $\\Delta$, $\\gamma$,  $\\lambda$,  $\\beta$,  $f(t)\\}$ where $f(t)$ is the logistic function to normalize the dimension of time, i.e., \n",
        "\n",
        "$$f(t) = a/(1 + b \\exp(-(t + c)/d))$$ \n",
        "\n",
        "where $a, b, c$ and  $d$ are constants. Check out the Supplementary Figure 3 of our AIQD papar [Predicting the future of excitation energy transfer in light-harvesting complex with artificial intelligence-based quantum dynamics](https://doi.org/10.1038/s41467-022-29621-w \"Named link title\"). \n",
        "\n",
        "For each time-step, the AIQD approach predicts and was trained on the corresponding reduced density matrix in the following format $\\mathcal{R}[\\rho_{11}(t)], \\mathcal{R}[\\rho_{1N}(t)], \\mathcal{I}[\\rho_{1N}(t)] \\dots, \\mathcal{R}[\\rho_{1N}(t)], \\mathcal{I}[\\rho_{1N}(t)], \\mathcal{R}[\\rho_{22}(t)], \\dots, \\mathcal{R}[\\rho_{2N}(t)], \\mathcal{I}[\\rho_{2N}(t)], \\mathcal{R}[\\rho_{33}(t)], \\dots, \\mathcal{R}[\\rho_{3N}(t)],\\mathcal{I}[\\rho_{3N}(t)],\\dots, \\dots,   \\mathcal{R}[\\rho_{NN}(t)]$ where $N$ is the dimension of the reduced density matrix and $\\mathcal{R}$ and $\\mathcal{I}$ represent the real and imaginary parts of the off-diagonal terms, respectively.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d44d092",
      "metadata": {
        "id": "3d44d092"
      },
      "source": [
        "## User-Manual \n",
        "\n",
        "call ```quant_dyn``` with out passing any parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "98f30f33",
      "metadata": {
        "id": "98f30f33",
        "outputId": "85874c15-9d93-4e38-c39a-ffbd56c1c308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "MLQD is a python package developed for Machine Learning-based Quantum Dissipative Dynamics,\n",
            " \t\t\t\t  Version 1.0.0\n",
            "\t\t\t https://github.com/Arif-PhyChem/MLQD\n",
            "\n",
            " \t\t\t Copyright (c) 2022 Arif Ullah\n",
            "\n",
            "All rights reserved. This work is licensed under the Attribution-NonCommercial-NoDerivatives 4.0\n",
            " \t International http://creativecommons.org/licenses/by-nc-nd/4.0/) license.\n",
            "\t\t\t See LICENSE.CC-BY-NC-ND-4.0\n",
            "\n",
            "\n",
            "The above copyright notice and this permission notice shall be included \n",
            "in all copies or substantial portions of the Software.\n",
            "\n",
            "\n",
            "The software is provided \"as is\" without warranty of any kind, express or implied, \n",
            "including but not limited to the warranties ofmerchantability, fitness for a particular \n",
            "purpose and noninfringement. In no event shall the authors or copyright holders be \n",
            "liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, \n",
            "arising from, out of or in connection with the software or the use or other dealings in the software.\n",
            "\n",
            "\n",
            "\t\t\t\t Cite as:\n",
            "\n",
            "1) Ullah A. and Dral P. O., New Journal of Physics, 2021, 23(11), 113019\n",
            "2) Ullah A. and Dral P. O., Nature Communications, 2022, 13(1), 1930\n",
            "3) Ullah A. and Dral P. O., Journal of Physical Chemistry Letters, 2022, 13(26), 6037\n",
            "4) Rodriguez L. E. H.; Ullah A.; Espinosa K. J. R.; Dral P. O. and A. A. Kananenka, Machine Learning: Science and Technology, 2022, 3(4), 045016\n",
            "\n",
            "Contributers List:\n",
            "\n",
            "1) Arif Ullah (main) \n",
            "2) Pavlo O. Dral\n",
            "\n",
            "=================================================================\n",
            "                            Manual                               \n",
            "=================================================================\n",
            "1]===> QDmodel (str): You can pass \"createQDmodel\" to train a QD model or \"useQDmodel\" to propagate dynamics with the already trained QD model. Default option is \"useQDmodel\"\n",
            "2]===> systemType (str): System type, you can pass \"SB\" for spin-boson model and \"FMO\" for FMO complex\n",
            "3]===> QDmodelOut (str): MLQD will save the trained QD model with this name. If you don not pass it, MLQD will pick a random name\n",
            "4]===> QDmodelIn (str): Pass the name of the trained QD model and MLQD will use it to predict dynamics\n",
            "5]===> QDtrajOut (str): MLQD will save the predicted trajectory with this name. If you do not pass a name, MLQD will pick a random name\n",
            "6]===> QDmodelType (str): Type of QD model. You can pass \"KRR\" for kernel ridge regression method, \"OSTL\" for OSTL approach and \"AIQD\" for AI-QD approach. The default option is OSTL\n",
            "7]===> prepInput (str): Choose wether you wanna prepare the input X and Y files from the data. You can pass \"True\" or \"False\". Default option is \"False\". For OSTL and AIQD, your data files should be in the same naming and file format as in out QD3SET-1 dataset\n",
            "8]===> time: (float): Propagation time in picoseconds (ps) for FMO complex and in atomic units (a.u.) for spin-boson model\n",
            "9]===> time_step (float): Time-step for time-propagation. Default values are 0.05 a.u. (for spin-boson model) and 5 fs for FMO complex\n",
            "10]===> hyperParam (str): Default option is \"False\". You can pass \"True\" (to optimize the hyperparameters) or \"False\" to not optimize the hyperparameters and run with the default structure\n",
            "11]===> XfileIn (str): The prepared X file will be saved at the provided file name, if not provided, MLQD will use the default name. In the case of KRR-based prediction of dynamics, this option provides the input short-time dynamics\n",
            "12]===> YfileIn (str): The prepared Y file will be saved at the provided file name. If not provided, MLQD will use the dafault name\n",
            "13]===> dataPath (str): MLQD will access data with this path and prepare the X and Y files\n",
            "\n",
            "------------------------------------------------------------------\n",
            "                Specific to AIQD and OSTL approach                \n",
            "------------------------------------------------------------------\n",
            "14]===> initState (int): Initial state with Initial Excitation. It is only required when propagating dynamics with OSTL or AIQD method for FMO complex. Default value is 1\n",
            "15]===> n_states (int): The number of states or sites. Default values are 2 for spin-boson model and 7 for FMO complex\n",
            "16]===> patience (int): Patience for early stopping in CNN training\n",
            "17]===> OptEpochs (int): The number of epochs for optimzation. Default value is 100\n",
            "18]===> TrEpochs (int): The number of epochs for training. Default value is 100\n",
            "19]===> max_evals (int): The number of maximum evaluations in hyperopt optimization. Default value is 100\n",
            "20]===> energyDiff (float): Energy difference between the two states in the case of spin-boson model. Default value is 1.0\n",
            "21]===> Delta (float): The tunneling matrix element in the case of spin-boson model. Default value is 1.0\n",
            "22]===> gamma (int): Characteristic frequency. Default values are 10 (spin-boson model) and 500 (FMO complex)\n",
            "23]===> lamb (int): System-bath coupling strength or the reorganization energy. Default values are 1 (spin-boson model) and 520 (FMO complex)\n",
            "24]===> temp (int): Temperature or inverse temperature. Default values are 1 (spin-boson model) and 510 (FMO complex)\n",
            "25]===> energyNorm (float): Normalizer for the energy difference between the states in the case of spin-boson model. Default value is 1.0\n",
            "26]===> DeltaNorm (float): Normalizer for the tunneling matrix element in the case of spin-boson model. Default value is 1.0\n",
            "27]===> gammaNorm (float): Normalizer for Characteristic frequency. Default values are 500 (FMO complex) and 10 (spin-boson model)\n",
            "28]===> lambNorm (float): Normalizer for System-bath coupling strength. Default values are 520 (FMO complex) and 1 (SB model)\n",
            "29]===> tempNorm (float): Normalizer for temperature or inverse temperature. Default values are 510 (FMO complex) and 1 (spin-boson model)\n",
            "\n",
            "------------------------------------------------------------------\n",
            "                     Specific to AIQD approach                    \n",
            "------------------------------------------------------------------\n",
            "30]===> numLogf (int): The number of Logistic functions for the normalization of time dimension. Default value is 1.0\n",
            "31]===> LogCa (float): Coefficient \"a\" in the logistic function, default value is 1.0\n",
            "32]===> LogCb (float): Coefficient \"b\" in the logistic function, default value is 15.0\n",
            "33]===> LogCc (float): Coefficient \"c\" in the logistic function, default value is -1.0\n",
            "34]===> LogCd (float): Coefficient \"d\" in the logistic function, default values is 1.0\n",
            "\n",
            "------------------------------------------------------------------\n",
            "                    Specific to KRR approach        \n",
            "------------------------------------------------------------------\n",
            "35]===> xlength (int): Length of the input short-time trajectory. It is the number of time steps in the data you pass with the \"dataCol\". Default value is 81\n",
            "36]===> krrSigma (float): If we pass \"False\" to hyperParam, then we need to provide a value for the hyperparameter Sigma in Gaussian kernel. Otherwise the model will run with the default value 4.0\n",
            "37]===> krrLamb (float): If we pass \"False\" to hyperParam, then we need to provide a value for the hyperparameter Lambda in KRR. Otherwise the model will run with the default value 0.00000001\n",
            "\n",
            "------------------------------------------------------------------\n",
            "                 Specific to KRR approach and Potting  \n",
            "------------------------------------------------------------------\n",
            "38]===> dataCol (int): The column number (counting starts from 0); As KRR is a single output model, and it is possible that you have many columns in your data files, using dataCol option, MLQD is able to grab only the mentioned column and train a KRR model on it. For plotting, the same option is used to grab the concerend column from the reference trajectory\n",
            "39]===> dtype (str): specify the data type. You can pass \"real\" or \"imag\". Default is \"real\". In KRR training, MLQD will extract the real or imaginary (imag) part of the column passed with \"dataCol\". For plotting, the same option is used the grab the concerned data type from the column of the reference trajectory\n",
            "\n",
            "------------------------------------------------------------------\n",
            "                        Specific to Plotting         \n",
            "------------------------------------------------------------------\n",
            "40]===> xlim (float): The xaxis limit while plotting\n",
            "41]===> pltNstates (int): The number of states to be plotted. Default option is to plot all states\n",
            "42]===> refTraj (str): MLQD will plot the predicted dynamics against this reference trajectory. If not provided, MLQD will ignore plotting\n",
            "=================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlqd.evolution.quant_dyn at 0x7f0139389520>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "quant_dyn()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3225d04",
      "metadata": {
        "id": "c3225d04"
      },
      "source": [
        "### 1. Training with preparation of training data and optimization of the CNN model\n",
        "\n",
        "For the sake of demonstration, we provide 20 trajectories in the MLQD GitHub repo. The trajectories are in the ```Jupyter_Notebooks/sb_data``` folder. Each trajectory is propagated with HEOM method upto ```t= 20 (a.u.)``` with time-step ```dt = 0.05```. You can check out our QD3SET-1 database for complete data sets https://doi.org/10.48550/arXiv.2301.12096"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the MLQD repo from GitHub\n",
        "!git clone https://github.com/Arif-PhyChem/MLQD.git\n",
        "!ls MLQD/Jupyter_Notebooks/sb_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7qjO3s8yrxu",
        "outputId": "30c9e17f-c60a-4bce-fb4e-90147e6b8c0c"
      },
      "id": "F7qjO3s8yrxu",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MLQD' already exists and is not an empty directory.\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-10.0_beta-0.1.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-10.0_beta-0.25.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-10.0_beta-0.5.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-10.0_beta-0.75.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-10.0_beta-1.0.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-1.0_beta-0.1.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-1.0_beta-0.25.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-1.0_beta-0.5.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-1.0_beta-0.75.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-1.0_beta-1.0.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-2.0_beta-0.1.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-2.0_beta-0.25.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-2.0_beta-0.5.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-2.0_beta-0.75.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-2.0_beta-1.0.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-3.0_beta-0.1.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-3.0_beta-0.25.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-3.0_beta-0.5.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-3.0_beta-0.75.npy\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-3.0_beta-1.0.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "afe1ab52",
      "metadata": {
        "id": "afe1ab52",
        "outputId": "4a28cd3f-4123-4a1c-8047-6c9623eaa94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "MLQD is a python package developed for Machine Learning-based Quantum Dissipative Dynamics,\n",
            " \t\t\t\t  Version 1.0.0\n",
            "\t\t\t https://github.com/Arif-PhyChem/MLQD\n",
            "\n",
            " \t\t\t Copyright (c) 2022 Arif Ullah\n",
            "\n",
            "All rights reserved. This work is licensed under the Attribution-NonCommercial-NoDerivatives 4.0\n",
            " \t International http://creativecommons.org/licenses/by-nc-nd/4.0/) license.\n",
            "\t\t\t See LICENSE.CC-BY-NC-ND-4.0\n",
            "\n",
            "\n",
            "The above copyright notice and this permission notice shall be included \n",
            "in all copies or substantial portions of the Software.\n",
            "\n",
            "\n",
            "The software is provided \"as is\" without warranty of any kind, express or implied, \n",
            "including but not limited to the warranties ofmerchantability, fitness for a particular \n",
            "purpose and noninfringement. In no event shall the authors or copyright holders be \n",
            "liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, \n",
            "arising from, out of or in connection with the software or the use or other dealings in the software.\n",
            "\n",
            "\n",
            "\t\t\t\t Cite as:\n",
            "\n",
            "1) Ullah A. and Dral P. O., New Journal of Physics, 2021, 23(11), 113019\n",
            "2) Ullah A. and Dral P. O., Nature Communications, 2022, 13(1), 1930\n",
            "3) Ullah A. and Dral P. O., Journal of Physical Chemistry Letters, 2022, 13(26), 6037\n",
            "4) Rodriguez L. E. H.; Ullah A.; Espinosa K. J. R.; Dral P. O. and A. A. Kananenka, Machine Learning: Science and Technology, 2022, 3(4), 045016\n",
            "\n",
            "Contributers List:\n",
            "\n",
            "1) Arif Ullah (main) \n",
            "2) Pavlo O. Dral\n",
            "=================================================================\n",
            "MLQD is started at 2023-03-28 10:55:24.883354\n",
            "=================================================================\n",
            "Setting \"systemType\" to SB\n",
            "MLQD is running with the option QDmodel =  createQDmodel\n",
            "Setting ML Model Type \"QDmodelType\" to AIQD\n",
            "Setting number of states \"n_states\" to 2\n",
            "Setting option \"prepInput\" to True\n",
            "Model will be saved as AIQD_SB_model\n",
            "Xfilein is x_data_aiqd\n",
            "YfileIn is y_data_aiqd\n",
            "You have chosen to optimize the hyper parameters of the model\n",
            "=================================================================\n",
            "Setting patience for early stopping to 10\n",
            "Setting number of epochs in hyperopt optimization to 10\n",
            "Setting number of epochs for training to 10\n",
            "Setting maximum number of evaluations to 1\n",
            "Setting energy difference normalizer \"energyNorm\" to 1.0\n",
            "Setting tunneling matrix element normalizer \"DeltaNorm\" to 1.0\n",
            "Setting gamma normalizeer \"gammaNorm\" to 10\n",
            "Setting lambda normalizer \"lambNormalizer\" to 1.0\n",
            "Setting temperature (or inverse temperature) normalizer \"tempNorm\" to 1.0\n",
            "=================================================================\n",
            "Setting number of Logistic functions to 10\n",
            "Setting \"a\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to 1.0\n",
            "Setting \"b\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to 15.0\n",
            "Setting \"c\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to -1.0\n",
            "Setting \"c\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to 1.0\n",
            "Setting propagation time \"time\" to 20\n",
            "Setting time_step to 0.05\n",
            "=================================================================\n",
            "=================================================================\n",
            "Normalization constants and constants for Logistic-function are dumped at AIQD_SB_model.pkl\n",
            "=================================================================\n",
            "train_ml.AIQD: preparing training data for AIQD model\n",
            "=================================================================\n",
            "prep_input.AIQD: Grabbing data from \" MLQD/Jupyter_Notebooks/sb_data \" directory\n",
            "prep_input.AIQD: It is assumed that the data is in the same naming format and the same datatype as were adopted in our QD3SET-1 dataset , otherwise training files will not be successfully generated\n",
            "prep_input.AIQD: Number of trajectories = 20\n",
            "prep_input.AIQD: Normalizing gamma, lambda and temperature using the following normalizing factors in their respective order: 10 1.0 1.0\n",
            "prep_input.AIQD: The input and target values are saved as x_data_aiqd.npy and y_data_aiqd.npy , respectively.\n",
            "=================================================================\n",
            "Train_ml.AIQD: Going for hyperopt optimization of CNN\n",
            "=================================================================\n",
            "Data: Checking to see whether the input data files x_data_aiqd.npy and y_data_aiqd.npy exist\n",
            "Data: Loading data files x_data_aiqd.npy y_data_aiqd.npy\n",
            "Data: splitting data into 80/20 % ratio (training/validation set)\n",
            "hyperopt_optim: Optimizing the Neural Network with hyperopt library\n",
            "hyperopt_optim: Setting Optimizer to Adam and loss to mean square error (mse)\n",
            "hyperopt_optim: We do not optimize the activation function and set it equal to Relu\n",
            "hyperopt_optim: Maximum number of evaluations = 1\n",
            "hyperopt_optim: Each evaluation runs for 10 epochs\n",
            "=================================================================\n",
            "Epoch 1/10\n",
            "\n",
            "401/401 - 7s - loss: 0.0201 - val_loss: 0.0134 - 7s/epoch - 17ms/step\n",
            "\n",
            "Epoch 2/10\n",
            "\n",
            "401/401 - 6s - loss: 0.0119 - val_loss: 0.0110 - 6s/epoch - 15ms/step\n",
            "\n",
            "Epoch 3/10\n",
            "\n",
            "401/401 - 6s - loss: 0.0101 - val_loss: 0.0093 - 6s/epoch - 16ms/step\n",
            "\n",
            "Epoch 4/10\n",
            "\n",
            "401/401 - 4s - loss: 0.0085 - val_loss: 0.0080 - 4s/epoch - 11ms/step\n",
            "\n",
            "Epoch 5/10\n",
            "\n",
            "401/401 - 3s - loss: 0.0075 - val_loss: 0.0070 - 3s/epoch - 7ms/step\n",
            "\n",
            "Epoch 6/10\n",
            "\n",
            "401/401 - 3s - loss: 0.0067 - val_loss: 0.0065 - 3s/epoch - 8ms/step\n",
            "\n",
            "Epoch 7/10\n",
            "\n",
            "401/401 - 4s - loss: 0.0059 - val_loss: 0.0054 - 4s/epoch - 10ms/step\n",
            "\n",
            "Epoch 8/10\n",
            "\n",
            "401/401 - 3s - loss: 0.0052 - val_loss: 0.0046 - 3s/epoch - 7ms/step\n",
            "\n",
            "Epoch 9/10\n",
            "\n",
            "401/401 - 3s - loss: 0.0042 - val_loss: 0.0037 - 3s/epoch - 7ms/step\n",
            "\n",
            "Epoch 10/10\n",
            "\n",
            "401/401 - 3s - loss: 0.0034 - val_loss: 0.0033 - 3s/epoch - 7ms/step\n",
            "\n",
            "100%|██████████| 1/1 [00:43<00:00, 43.20s/trial, best loss: 0.0032627435866743326]\n",
            "Train_ml.OSTL: Time taken for optimization = 43.24608755111694 sec\n",
            "Train_ml.AIQD: Training CNN model with the optimized hyper_parameters\n",
            "=================================================================\n",
            "Data: Checking to see whether the input data files x_data_aiqd.npy and y_data_aiqd.npy exist\n",
            "Data: Loading data files x_data_aiqd.npy y_data_aiqd.npy\n",
            "Data: splitting data into 80/20 % ratio (training/validation set)\n",
            "=================================================================\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 8, 190)            1710      \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 8, 70)             39970     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 4, 70)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 280)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               71936     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 247,252\n",
            "Trainable params: 247,252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "=================================================================\n",
            "cnn.CNN_optim: Running wth EarlyStopping of patience = 10\n",
            "cnn.CNN_optim: Running with batch size = 16 and epochs = 10\n",
            "=================================================================\n",
            "Epoch 1/10\n",
            "401/401 - 5s - loss: 0.0199 - val_loss: 0.0134 - 5s/epoch - 12ms/step\n",
            "Epoch 2/10\n",
            "401/401 - 3s - loss: 0.0120 - val_loss: 0.0117 - 3s/epoch - 7ms/step\n",
            "Epoch 3/10\n",
            "401/401 - 3s - loss: 0.0104 - val_loss: 0.0097 - 3s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "401/401 - 4s - loss: 0.0088 - val_loss: 0.0086 - 4s/epoch - 9ms/step\n",
            "Epoch 5/10\n",
            "401/401 - 3s - loss: 0.0078 - val_loss: 0.0074 - 3s/epoch - 8ms/step\n",
            "Epoch 6/10\n",
            "401/401 - 3s - loss: 0.0070 - val_loss: 0.0067 - 3s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "401/401 - 3s - loss: 0.0063 - val_loss: 0.0061 - 3s/epoch - 7ms/step\n",
            "Epoch 8/10\n",
            "401/401 - 3s - loss: 0.0056 - val_loss: 0.0052 - 3s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "401/401 - 4s - loss: 0.0049 - val_loss: 0.0049 - 4s/epoch - 9ms/step\n",
            "Epoch 10/10\n",
            "401/401 - 3s - loss: 0.0042 - val_loss: 0.0038 - 3s/epoch - 7ms/step\n",
            "=================================================================\n",
            "cnn.CNN_optim: OSTL model is saved as \" AIQD_SB_model.hdf5 \"\n",
            "Train_ml.AIQD: Time taken for training = 42.707295179367065 sec\n",
            "Train_ml.AIQD: Total Time (optimization + training) = 85.9536190032959 sec\n",
            "=================================================================\n",
            "=================================================================\n",
            "MLQD is ended at 2023-03-28 10:56:50.939128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlqd.evolution.quant_dyn at 0x7f013933c220>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "param={ \n",
        "        'n_states': 2,                  # int:  Number of states (SB) or sites (FMO), default 2 (SB) and 7 (FMO).\n",
        "        'time': 20,                     # float: Propagation time in picoseconds (ps) for FMO complex and in (a.u.) for spin-boson model\n",
        "        'time_step': 0.05,              # float: Time-step for time-propagation. Default values are 0.05 (spin-boson model) and 0.005ps for FMO complex.\n",
        "        'QDmodel': 'createQDmodel',     # string: createQDmodel, the dafault option is useQDmodel\n",
        "        'QDmodelType': 'AIQD',          # string: Type of model. The default option is OSTL\n",
        "        'prepInput' : 'True',           # str: Prepare input files from the data (Default 'False')\n",
        "        'XfileIn': 'x_data_aiqd',       # str: (Optional, npy file) The prepared X file will be saved at the provided file name \n",
        "        'YfileIn': 'y_data_aiqd',       # str: (Optional, npy file) The prepared Y file will be saved at the provided file name \n",
        "        'numLogf': 10,                  # int: Number of Logistic function for the normalization of time dimension. Default value is 1.0.    \n",
        "        'LogCa' : 1.0,                  # float: Coefficient \"a\" in the logistic function, default values is 1.0 (you may not provide it)\n",
        "        'LogCb' : 15.0,                 # float: Coefficient \"b\" in the logistic function, default values is 15.0 (you may not provide it)\n",
        "        'LogCc' : -1.0,                 # float: Coefficient \"a\" in the logistic function, default values is -1.0 (you may not provide it)\n",
        "        'LogCd' : 1.0,                  # float: Coefficient \"d\" in the logistic function, default values is 1.0 (you may not provide it)\n",
        "        'energyNorm': 1.0,              # float: Normalizer for energy difference. Default value is 1.0 (adopted in the provided trained models)\n",
        "        'DeltaNorm': 1.0,               # float: Normalizer for Delta. Default value is 1.0 (adopted in the provided trained models)\n",
        "        'gammaNorm': 10,                # float: Normalizer for Characteristic frequency. Default value is 500 in the case of FMO complex and 10 in the case of spin-boson model. The same values are also adopted in the provided trained models  \n",
        "        'lambNorm': 1.0,                # float: Normalizer for System-bath coupling strength. Default value is 520 (FMO complex) and 1 (SB model). The same values are also adopted in the provided trained models \n",
        "        'tempNorm': 1.0,                # float: Normalizer for temperature. Default value is 510 (FMO complex) and 1 (SB model). The same values are also adopted in the provided trained models.\n",
        "        'systemType': 'SB',             # str: (Not optional) Need to define, wether your model is spin-boson (SB) or FMO complex (FMO) \n",
        "        'hyperParam': 'True',           # str: Default is 'False', we can pass 'True' (optimize the hyperparameters) or 'False' (don't optimize and run with the default structure)\n",
        "        'patience': 10,                 # Int: Patience for early stopping in CNN training \n",
        "        'OptEpochs': 10,                # int: Number of epochs for CNN optimization \n",
        "        'TrEpochs': 10,                 # int: Number of epochs for CNN training  \n",
        "        'max_evals': 1,                 # int: Maximum number of evaluations in the case of hyperopt optimization\n",
        "        'dataPath': 'MLQD/Jupyter_Notebooks/sb_data',          # str: Data path\n",
        "        'QDmodelOut': 'AIQD_SB_model'   # str: (Optional), providing a name to save the model at\n",
        "        }\n",
        "    \n",
        "quant_dyn(**param)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed22361",
      "metadata": {
        "id": "aed22361"
      },
      "source": [
        "### 2. Training with preparation of training data but No optimization of the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d797e7d",
      "metadata": {
        "id": "9d797e7d",
        "outputId": "a2cf5315-89a5-406b-8c13-6a2fd6be6f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "MLQD is a python package developed for Machine Learning-based Quantum Dissipative Dynamics,\n",
            " \t\t\t\t  Version 1.0.0\n",
            "\t\t\t https://github.com/Arif-PhyChem/MLQD\n",
            "\n",
            " \t\t\t Copyright (c) 2022 Arif Ullah\n",
            "\n",
            "All rights reserved. This work is licensed under the Attribution-NonCommercial-NoDerivatives 4.0\n",
            " \t International http://creativecommons.org/licenses/by-nc-nd/4.0/) license.\n",
            "\t\t\t See LICENSE.CC-BY-NC-ND-4.0\n",
            "\n",
            "\n",
            "The above copyright notice and this permission notice shall be included \n",
            "in all copies or substantial portions of the Software.\n",
            "\n",
            "\n",
            "The software is provided \"as is\" without warranty of any kind, express or implied, \n",
            "including but not limited to the warranties ofmerchantability, fitness for a particular \n",
            "purpose and noninfringement. In no event shall the authors or copyright holders be \n",
            "liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, \n",
            "arising from, out of or in connection with the software or the use or other dealings in the software.\n",
            "\n",
            "\n",
            "\t\t\t\t Cite as:\n",
            "\n",
            "1) Ullah A. and Dral P. O., New Journal of Physics, 2021, 23(11), 113019\n",
            "2) Ullah A. and Dral P. O., Nature Communications, 2022, 13(1), 1930\n",
            "3) Ullah A. and Dral P. O., Journal of Physical Chemistry Letters, 2022, 13(26), 6037\n",
            "4) Rodriguez L. E. H.; Ullah A.; Espinosa K. J. R.; Dral P. O. and A. A. Kananenka, Machine Learning: Science and Technology, 2022, 3(4), 045016\n",
            "\n",
            "Contributers List:\n",
            "\n",
            "1) Arif Ullah (main) \n",
            "2) Pavlo O. Dral\n",
            "=================================================================\n",
            "MLQD is started at 2023-03-28 10:56:50.966702\n",
            "=================================================================\n",
            "Setting \"systemType\" to SB\n",
            "MLQD is running with the option QDmodel =  createQDmodel\n",
            "Setting ML Model Type \"QDmodelType\" to AIQD\n",
            "Setting number of states \"n_states\" to 2\n",
            "Setting option \"prepInput\" to True\n",
            "Model will be saved as AIQD_SB_model\n",
            "Xfilein is x_data_aiqd\n",
            "YfileIn is y_data_aiqd\n",
            "You have chosen not to optimize the hyper parameters of the model, otherwise you should pass \"True\" to hyperParam\n",
            "=================================================================\n",
            "Setting patience for early stopping to 10\n",
            "Running with the dafualt value of \"Optimization epochs\" = 100\n",
            "Setting number of epochs for training to 10\n",
            "Setting energy difference normalizer \"energyNorm\" to 1.0\n",
            "Setting tunneling matrix element normalizer \"DeltaNorm\" to 1.0\n",
            "Setting gamma normalizeer \"gammaNorm\" to 10\n",
            "Setting lambda normalizer \"lambNormalizer\" to 1.0\n",
            "Setting temperature (or inverse temperature) normalizer \"tempNorm\" to 1.0\n",
            "=================================================================\n",
            "Setting number of Logistic functions to 10\n",
            "Setting \"a\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to 1.0\n",
            "Setting \"b\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to 15.0\n",
            "Setting \"c\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to -1.0\n",
            "Setting \"c\" in Logistic function f(t) = a/(1 + b * np.exp(-(t-c)/d))) to 1.0\n",
            "Setting propagation time \"time\" to 20\n",
            "Setting time_step to 0.05\n",
            "=================================================================\n",
            "=================================================================\n",
            "Normalization constants and constants for Logistic-function are dumped at AIQD_SB_model.pkl\n",
            "=================================================================\n",
            "train_ml.AIQD: preparing training data for AIQD model\n",
            "=================================================================\n",
            "prep_input.AIQD: Grabbing data from \" MLQD/Jupyter_Notebooks/sb_data \" directory\n",
            "prep_input.AIQD: It is assumed that the data is in the same naming format and the same datatype as were adopted in our QD3SET-1 dataset , otherwise training files will not be successfully generated\n",
            "prep_input.AIQD: Number of trajectories = 20\n",
            "prep_input.AIQD: Normalizing gamma, lambda and temperature using the following normalizing factors in their respective order: 10 1.0 1.0\n",
            "prep_input.AIQD: The input and target values are saved as x_data_aiqd.npy and y_data_aiqd.npy , respectively.\n",
            "=================================================================\n",
            "Train.ml_AIQD: Looking for best_param.pkl\n",
            "=================================================================\n",
            "Train.ml_AIQD: loading hyperparameters from best_param.pkl\n",
            "Data: Checking to see whether the input data files x_data_aiqd.npy and y_data_aiqd.npy exist\n",
            "Data: Loading data files x_data_aiqd.npy y_data_aiqd.npy\n",
            "Data: splitting data into 80/20 % ratio (training/validation set)\n",
            "=================================================================\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 8, 190)            1710      \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 8, 70)             39970     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 4, 70)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 280)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               71936     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 247,252\n",
            "Trainable params: 247,252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "=================================================================\n",
            "cnn.CNN_optim: Running wth EarlyStopping of patience = 10\n",
            "cnn.CNN_optim: Running with batch size = 16 and epochs = 10\n",
            "=================================================================\n",
            "Epoch 1/10\n",
            "401/401 - 4s - loss: 0.0194 - val_loss: 0.0135 - 4s/epoch - 11ms/step\n",
            "Epoch 2/10\n",
            "401/401 - 5s - loss: 0.0121 - val_loss: 0.0114 - 5s/epoch - 14ms/step\n",
            "Epoch 3/10\n",
            "401/401 - 5s - loss: 0.0103 - val_loss: 0.0093 - 5s/epoch - 13ms/step\n",
            "Epoch 4/10\n",
            "401/401 - 6s - loss: 0.0086 - val_loss: 0.0079 - 6s/epoch - 15ms/step\n",
            "Epoch 5/10\n",
            "401/401 - 4s - loss: 0.0076 - val_loss: 0.0071 - 4s/epoch - 11ms/step\n",
            "Epoch 6/10\n",
            "401/401 - 3s - loss: 0.0067 - val_loss: 0.0063 - 3s/epoch - 8ms/step\n",
            "Epoch 7/10\n",
            "401/401 - 5s - loss: 0.0059 - val_loss: 0.0055 - 5s/epoch - 13ms/step\n",
            "Epoch 8/10\n",
            "401/401 - 3s - loss: 0.0050 - val_loss: 0.0045 - 3s/epoch - 8ms/step\n",
            "Epoch 9/10\n",
            "401/401 - 3s - loss: 0.0039 - val_loss: 0.0036 - 3s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "401/401 - 3s - loss: 0.0030 - val_loss: 0.0027 - 3s/epoch - 8ms/step\n"
          ]
        }
      ],
      "source": [
        "param={ \n",
        "        'n_states': 2,                  # int:  Number of states (SB) or sites (FMO), default 2 (SB) and 7 (FMO).\n",
        "        'time': 20,                     # float: Propagation time in picoseconds (ps) for FMO complex and in (a.u.) for spin-boson model\n",
        "        'time_step': 0.05,              # float: Time-step for time-propagation. Default values are 0.05 (spin-boson model) and 0.005ps for FMO complex.\n",
        "        'QDmodel': 'createQDmodel',     # string: createQDmodel, the dafault option is useQDmodel\n",
        "        'QDmodelType': 'AIQD',          # string: Type of model. The default option is OSTL\n",
        "        'prepInput' : 'True',           # str: Prepare input files from the data (Default 'False')\n",
        "        'XfileIn': 'x_data_aiqd',       # str: (Optional, npy file) The prepared X file will be saved at the provided file name \n",
        "        'YfileIn': 'y_data_aiqd',       # str: (Optional, npy file) The prepared Y file will be saved at the provided file name \n",
        "        'numLogf': 10,                  # int: Number of Logistic function for the normalization of time dimension. Default value is 1.0.    \n",
        "        'LogCa' : 1.0,                  # float: Coefficient \"a\" in the logistic function, default values is 1.0 (you may not provide it)\n",
        "        'LogCb' : 15.0,                 # float: Coefficient \"b\" in the logistic function, default values is 15.0 (you may not provide it)\n",
        "        'LogCc' : -1.0,                 # float: Coefficient \"a\" in the logistic function, default values is -1.0 (you may not provide it)\n",
        "        'LogCd' : 1.0,                  # float: Coefficient \"d\" in the logistic function, default values is 1.0 (you may not provide it)\n",
        "        'energyNorm': 1.0,              # float: Normalizer for energy difference. Default value is 1.0 (adopted in the provided trained models)\n",
        "        'DeltaNorm': 1.0,               # float: Normalizer for Delta. Default value is 1.0 (adopted in the provided trained models)\n",
        "        'gammaNorm': 10,                # float: Normalizer for Characteristic frequency. Default value is 500 in the case of FMO complex and 10 in the case of spin-boson model. The same values are also adopted in the provided trained models  \n",
        "        'lambNorm': 1.0,                # float: Normalizer for System-bath coupling strength. Default value is 520 (FMO complex) and 1 (SB model). The same values are also adopted in the provided trained models \n",
        "        'tempNorm': 1.0,                # float: Normalizer for temperature. Default value is 510 (FMO complex) and 1 (SB model). The same values are also adopted in the provided trained models.\n",
        "        'systemType': 'SB',             # str: (Not optional) Need to define, wether your model is spin-boson (SB) or FMO complex (FMO) \n",
        "        'hyperParam': 'False',          # str: Default is 'False', we can pass 'True' (optimize the hyperparameters) or 'False' (don't optimize and run with the default structure)\n",
        "        'patience': 10,                 # Int: Patience for early stopping in CNN training \n",
        "        'TrEpochs': 10,                 # int: Number of epochs for CNN training  \n",
        "        'dataPath': 'MLQD/Jupyter_Notebooks/sb_data',          # str: Data path\n",
        "        'QDmodelOut': 'AIQD_SB_model'   # str: (Optional), providing a name to save the model at\n",
        "        }\n",
        "    \n",
        "quant_dyn(**param)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549d5769",
      "metadata": {
        "id": "549d5769"
      },
      "source": [
        "### 3. Training without preparation of training data and optimization of the CNN model. \n",
        "\n",
        "In this example, we will not prepare the training data and will directly pass the X and Y files as were prepared in demonstration 1 or 2. Here we still need to provide the normalization constants in order to save them.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42d6e1c",
      "metadata": {
        "id": "e42d6e1c"
      },
      "outputs": [],
      "source": [
        "param={ \n",
        "        'n_states': 2,                  # int:  Number of states (SB) or sites (FMO), default 2 (SB) and 7 (FMO).\n",
        "        'QDmodel': 'createQDmodel',     # str: createQDmodel, the dafault option is useQDmodel\n",
        "        'QDmodelType': 'AIQD',          # str: Type of model. The default option is OSTL\n",
        "        'prepInput' : 'False',          # str: Do not prepare input files from the data (Default is also 'False')\n",
        "        'systemType': 'SB',             # str: (Not optional) Need to define, wether your model is spin-boson (SB) or FMO complex (FMO) \n",
        "        'XfileIn': 'x_data_aiqd',       # str: (Not Optional, npy file) The X file \n",
        "        'YfileIn': 'y_data_aiqd',       # str: (Not Optional, npy file) The X file \n",
        "        'numLogf': 10,                  # int: Number of Logistic function for the normalization of time dimension. Default value is 1.0.    \n",
        "        'LogCa' : 1.0,                  # float: Coefficient \"a\" in the logistic function, default values is 1.0 (you may not provide it)\n",
        "        'LogCb' : 15.0,                 # float: Coefficient \"b\" in the logistic function, default values is 15.0 (you may not provide it)\n",
        "        'LogCc' : -1.0,                 # float: Coefficient \"a\" in the logistic function, default values is -1.0 (you may not provide it)\n",
        "        'LogCd' : 1.0,                  # float: Coefficient \"d\" in the logistic function, default values is 1.0 (you may not provide it)\n",
        "        'energyNorm': 1.0,              # float: Normalizer for energy difference. Default value is 1.0 (adopted in the provided trained models)\n",
        "        'DeltaNorm': 1.0,               # float: Normalizer for Delta. Default value is 1.0 (adopted in the provided trained models)\n",
        "        'gammaNorm': 10,                # float: Normalizer for Characteristic frequency. Default value is 500 in the case of FMO complex and 10 in the case of spin-boson model. The same values are also adopted in the provided trained models  \n",
        "        'lambNorm': 1.0,                # float: Normalizer for System-bath coupling strength. Default value is 520 (FMO complex) and 1 (SB model). The same values are also adopted in the provided trained models \n",
        "        'tempNorm': 1.0,                # float: Normalizer for temperature. Default value is 510 (FMO complex) and 1 (SB model). The same values are also adopted in the provided trained models.\n",
        "        'hyperParam': 'False',          # str: Default is 'False', we can pass 'True' (optimize the hyperparameters) or 'False' (don't optimize and run with the default structure)\n",
        "        'patience': 10,                 # int: Patience for early stopping in CNN training\n",
        "        'TrEpochs': 10,                 # int: Number of epochs for CNN training  \n",
        "        'QDmodelOut': 'AIQD_SB_model'   # str: (Optional), providing a name to save the model at\n",
        "        }\n",
        "quant_dyn(**param)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd502de",
      "metadata": {
        "id": "8fd502de"
      },
      "source": [
        "# Propagating dynamics with the trained AIQD model \n",
        "\n",
        "Here we will demonstrate how to propagate dynamics with the model we trained above \"AIQD_FMO_model.hdf5\". We will provide the simulation parameters and the AIQD will predict the corresponding dynamics. **While training the model, the normalization constants for $\\epsilon, \\Delta, \\gamma, \\lambda$ and $\\beta$, number of Logistic functions and constants for Logistic function, i.e, $a, b, c, d$ were saved as a pickle file (with the similar name as the model name). Thus the user does not need to provide, MLQD will automatically load them.** \n",
        "\n",
        "***MLQD is also able to plot the dynamics against the reference trajectory***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6911ff5d",
      "metadata": {
        "id": "6911ff5d"
      },
      "outputs": [],
      "source": [
        "param={ \n",
        "        'n_states': 2,                          # Int:  Number of states (SB) or sites (FMO). Default is 2 (SB) and 7 (FMO).\n",
        "        'time': 20,                             # float: Propagation time in picoseconds (ps)  for FMO complex and in (a.u.) for spin-boson model\n",
        "        'time_step': 0.05,                      # float: Time-step for time-propagation (you are not restricted to the time-step used in the training data, however better stick to that for good accuracy) Default values are 0.05 (a.u.) for spin-boson model and 5fs for FMO complex\n",
        "        'energyDiff': 0.0,                      # float: Energy difference between the two states (in the unit of (a.u.)). Only required in SB model\n",
        "        'Delta': 1.0,                           # float: The tunneling matrix element (in the unit of (a.u.)). Only required in SB model\n",
        "        'gamma': 4.0,                           # float: Characteristic frequency (in cm^-1 for the provided trained FMO models, in (a.u.) for spin-boson model)\n",
        "        'lamb': 0.1,                            # float: System-bath coupling strength  (in cm^-1 for the provided trained FMO models, in (a.u.) for spin-boson model)\n",
        "        'temp': 1.0,                            # float: temperature in K  (in Kilven for the provided trained FMO models, in (a.u.) for spin-boson model)\n",
        "        'QDmodel': 'useQDmodel',                # str: In MLQD, the dafault option is useQDmodel tells the MLQD to propagate dynamics with an existing trained model\n",
        "        'QDmodelType': 'AIQD',                  # str: The type of model we wanna use, here AIQD. The default option is OSTL\n",
        "        'systemType': 'SB',                     # str: (Not optional)  Need to define, wether your model is spin-boson (SB) or FMO complex (FMO) \n",
        "        'QDmodelIn': 'AIQD_SB_model.hdf5',      # str: (Not Optional for useQDmodel), provide the name of the trained ML model\n",
        "        'QDtrajOut': 'Qd_trajectory',           # str: (Optional), File name where the trajectory should be saved\n",
        "        'xlim': 20,                             # Xaxis limit for plotting. Default is equal to propagation time\n",
        "        'pltNstates': 2,                        # How many states to be plotted. Default option is to plot all\n",
        "        'refTraj':'MLQD/Jupyter_Notebooks/test_set/sb/2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-4.0_beta-1.0.npy' # Reference trajectory \n",
        "        }\n",
        "quant_dyn(**param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b832d5",
      "metadata": {
        "id": "b6b832d5"
      },
      "outputs": [],
      "source": [
        "heom_dyn = np.load('MLQD/Jupyter_Notebooks/test_set/sb/2_epsilon-0.0_Delta-1.0_lambda-0.1_gamma-4.0_beta-1.0.npy')\n",
        "pred_dyn = np.load('Qd_trajectory.npy')\n",
        "t_1 = np.real(heom_dyn[:,0])\n",
        "t_2 = np.real(pred_dyn[:,0])\n",
        "pred_state_1_pop = np.real(pred_dyn[:,1] - pred_dyn[:,4])\n",
        "heom_state_1_pop = np.real(heom_dyn[:,1] - heom_dyn[:,4])\n",
        "\n",
        "plt.rcParams['font.size'] = '20'\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(t_2, pred_state_1_pop, )\n",
        "plt.plot(t_1, heom_state_1_pop, '-.')\n",
        "plt.xlabel(r'$t \\ \\Delta$')\n",
        "plt.ylabel(r'$\\rho_{11}$')\n",
        "plt.legend([\"Predicted (AIQD)\", 'Reference (HEOM)'])\n",
        "plt.title('Time evolution of population \\n difference in the spin-boson model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fcdd1f8",
      "metadata": {
        "id": "9fcdd1f8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}